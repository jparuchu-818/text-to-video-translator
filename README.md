# ğŸ¬ Text-to-Video Generator

This project is an AI-powered **Text-to-Video Generation Pipeline** that transforms plain text into engaging short videos with **images, voiceovers, and cinematic effects**.  

It combines the power of **local AI models** for text-to-image, speech synthesis, and video composition â€” so you can generate videos completely offline.

---

## ğŸš€ Features
- ğŸ“ **Text Input** â†’ Enter or load a script/story.
- ğŸ–¼ **Image Generation** â†’ Uses Stable Diffusion to create scene visuals.
- ğŸ™ **Voice Narration** â†’ Converts text to natural speech (Hindi/English supported).
- ğŸ¥ **Video Composition** â†’ Combines images + voiceover with cinematic effects (zoom, pan, fade).
- ğŸ’¬ **Subtitles** â†’ Auto-generated captions in English.
- ğŸŒ **Offline Support** â†’ Works without internet once models are downloaded.

---

## ğŸ›  Tech Stack
- **Python 3.12+**
- [Stable Diffusion (Diffusers)](https://huggingface.co/docs/diffusers)
- [MoviePy](https://zulko.github.io/moviepy/)
- [gTTS / Coqui TTS](https://github.com/coqui-ai/TTS) for text-to-speech
- [Ollama](https://ollama.ai) for grammar/translation assistance
- Supporting libraries: `torch`, `transformers`, `pydub`, `sentence-transformers`

---

## ğŸ“‚ Project Structure
video-text/
â”‚â”€â”€ assets/ # Generated images/audio
â”‚â”€â”€ outputs/ # Final composed videos
â”‚â”€â”€ image_voice_generator.py
â”‚â”€â”€ video_composer.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
